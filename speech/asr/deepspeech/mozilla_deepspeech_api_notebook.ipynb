{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mozilla_deepspeech_api_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scgupta/yearn2learn/blob/master/speech/asr/deepspeech/mozilla_deepspeech_api_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utrU3Ul7KK0G",
        "colab_type": "text"
      },
      "source": [
        "# Mozilla DeepSpeech API Exploration\n",
        "\n",
        "Mozilla released [DeepSpeech 0.8.2](https://github.com/mozilla/DeepSpeech/releases/tag/v0.8.2) with [APIs in C, Java, .NET, Python, and JavaScript](https://deepspeech.readthedocs.io/en/v0.8.2/Python-API.html).\n",
        "\n",
        "From Colab menu, select: **Runtime** > **Change runtime type**, and verify that it is set to Python3, and select GPU if you want to try out GPU version.\n",
        "\n",
        "You can install DeepSpeech with pip (make it deepspeech-gpu==0.8.2 if you are using GPU in colab runtime):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iemeuv-jKR3P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "670c8023-4b23-4649-d60c-96404d490616"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zABV65yhNJ0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "8d6955bc-f572-410f-f5db-4955c8e47f83"
      },
      "source": [
        "!pip install deepspeech==0.8.2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepspeech==0.8.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/ff/f17ff70af03d27afb749f866cab2e6f5def29e02d5aa2762afc68ea92eab/deepspeech-0.8.2-cp36-cp36m-manylinux1_x86_64.whl (8.3MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3MB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepspeech==0.8.2) (1.18.5)\n",
            "Installing collected packages: deepspeech\n",
            "Successfully installed deepspeech-0.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbWIPOUwNVyI",
        "colab_type": "text"
      },
      "source": [
        "## Download Models and Audio Files\n",
        "\n",
        "Mozilla has released models for US English, we will use those in this code lab.\n",
        "\n",
        "1. **Download the models:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z0dSoLJPKKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir deepspeech-0.8.2-models"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpOO5HeBPZcY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "outputId": "f3fe083d-3e65-4bd5-b0fe-f10a35ca5da6"
      },
      "source": [
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.8.1/deepspeech-0.8.1-models.pbmm\n",
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.8.1/deepspeech-0.8.1-models.scorer"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-24 16:42:09--  https://github.com/mozilla/DeepSpeech/releases/download/v0.8.1/deepspeech-0.8.1-models.pbmm\n",
            "Resolving github.com (github.com)... 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/mozilla/STT/releases/download/v0.8.1/deepspeech-0.8.1-models.pbmm [following]\n",
            "--2020-08-24 16:42:09--  https://github.com/mozilla/STT/releases/download/v0.8.1/deepspeech-0.8.1-models.pbmm\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/60273704/ae836480-db4e-11ea-9bf7-2d4ba9ea96f3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200824%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200824T164209Z&X-Amz-Expires=300&X-Amz-Signature=53a83f7eaa1805af19f42192917a8cc264f10f6aafa08c5114fbad6793defb5b&X-Amz-SignedHeaders=host&actor_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.8.1-models.pbmm&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-08-24 16:42:09--  https://github-production-release-asset-2e65be.s3.amazonaws.com/60273704/ae836480-db4e-11ea-9bf7-2d4ba9ea96f3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200824%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200824T164209Z&X-Amz-Expires=300&X-Amz-Signature=53a83f7eaa1805af19f42192917a8cc264f10f6aafa08c5114fbad6793defb5b&X-Amz-SignedHeaders=host&actor_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.8.1-models.pbmm&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.11.148\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.11.148|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 188915984 (180M) [application/octet-stream]\n",
            "Saving to: ‘deepspeech-0.8.1-models.pbmm’\n",
            "\n",
            "deepspeech-0.8.1-mo 100%[===================>] 180.16M  34.2MB/s    in 5.8s    \n",
            "\n",
            "2020-08-24 16:42:16 (31.0 MB/s) - ‘deepspeech-0.8.1-models.pbmm’ saved [188915984/188915984]\n",
            "\n",
            "--2020-08-24 16:42:16--  https://github.com/mozilla/DeepSpeech/releases/download/v0.8.1/deepspeech-0.8.1-models.scorer\n",
            "Resolving github.com (github.com)... 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/mozilla/STT/releases/download/v0.8.1/deepspeech-0.8.1-models.scorer [following]\n",
            "--2020-08-24 16:42:16--  https://github.com/mozilla/STT/releases/download/v0.8.1/deepspeech-0.8.1-models.scorer\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/60273704/dd99d600-db4e-11ea-9f56-f897b9a8dc2a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200824%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200824T164216Z&X-Amz-Expires=300&X-Amz-Signature=be31835e876d79644b29eacf16f9df641b9a5a448a45a026e2939778d35c30e6&X-Amz-SignedHeaders=host&actor_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.8.1-models.scorer&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-08-24 16:42:16--  https://github-production-release-asset-2e65be.s3.amazonaws.com/60273704/dd99d600-db4e-11ea-9f56-f897b9a8dc2a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200824%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200824T164216Z&X-Amz-Expires=300&X-Amz-Signature=be31835e876d79644b29eacf16f9df641b9a5a448a45a026e2939778d35c30e6&X-Amz-SignedHeaders=host&actor_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.8.1-models.scorer&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.112.67\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.112.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 953363776 (909M) [application/octet-stream]\n",
            "Saving to: ‘deepspeech-0.8.1-models.scorer’\n",
            "\n",
            "deepspeech-0.8.1-mo 100%[===================>] 909.20M  35.1MB/s    in 27s     \n",
            "\n",
            "2020-08-24 16:42:44 (33.7 MB/s) - ‘deepspeech-0.8.1-models.scorer’ saved [953363776/953363776]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxa0os-3OA1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv deepspeech-0.8.1-models.pbmm deepspeech-0.8.1-models.scorer deepspeech-0.8.2-models/"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fu521L7QAxa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b0dc902d-7c25-4600-b771-966b92fc3997"
      },
      "source": [
        "!ls -l deepspeech-0.8.2-models/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1115520\n",
            "-rw-r--r-- 1 root root 188915984 Aug 10 19:15 deepspeech-0.8.1-models.pbmm\n",
            "-rw-r--r-- 1 root root 953363776 Aug 10 19:17 deepspeech-0.8.1-models.scorer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g5hZVWXO1wl",
        "colab_type": "text"
      },
      "source": [
        "2. **Download audio data files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8r7m0zlO_BJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "e7e15b40-fe1c-4d50-bb9f-7bbcb57f5c14"
      },
      "source": [
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.8.2/audio-0.8.2.tar.gz"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   140  100   140    0     0    933      0 --:--:-- --:--:-- --:--:--   933\n",
            "100   629  100   629    0     0   1947      0 --:--:-- --:--:-- --:--:--  1947\n",
            "100  194k  100  194k    0     0   189k      0  0:00:01  0:00:01 --:--:-- 1488k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4yZaht2PH_5",
        "colab_type": "text"
      },
      "source": [
        "4. **Unzip audio files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82DLg4JpPOVX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "3eb61754-d0c4-4ea4-d612-986340b4bd80"
      },
      "source": [
        "!tar -xvzf audio-0.8.2.tar.gz"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "._audio\n",
            "audio/\n",
            "audio/._2830-3980-0043.wav\n",
            "audio/2830-3980-0043.wav\n",
            "audio/._Attribution.txt\n",
            "audio/Attribution.txt\n",
            "audio/._4507-16021-0012.wav\n",
            "audio/4507-16021-0012.wav\n",
            "audio/._8455-210777-0068.wav\n",
            "audio/8455-210777-0068.wav\n",
            "audio/._License.txt\n",
            "audio/License.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zExydudVPU4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "bfdaaadb-0046-4a2c-8e94-fc3e420b08f2"
      },
      "source": [
        "!ls -l ./audio/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 260\n",
            "-rw-r--r-- 1 501 staff 63244 Nov 18  2017 2830-3980-0043.wav\n",
            "-rw-r--r-- 1 501 staff 87564 Nov 18  2017 4507-16021-0012.wav\n",
            "-rw-r--r-- 1 501 staff 82924 Nov 18  2017 8455-210777-0068.wav\n",
            "-rw-r--r-- 1 501 staff   340 May 14  2018 Attribution.txt\n",
            "-rw-r--r-- 1 501 staff 18652 May 12  2018 License.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIiwclaXPzfm",
        "colab_type": "text"
      },
      "source": [
        "5. **Test that it all works**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlXV9XlpP8k2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "727f2f6c-0a74-4ad6-9d33-45b8225b3137"
      },
      "source": [
        "!deepspeech --model deepspeech-0.8.2-models/deepspeech-0.8.1-models.pbmm --scorer deepspeech-0.8.2-models/deepspeech-0.8.1-models.scorer --audio ./audio/2830-3980-0043.wav"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from file deepspeech-0.8.2-models/deepspeech-0.8.1-models.pbmm\n",
            "TensorFlow: v2.2.0-24-g1c1b2b9\n",
            "DeepSpeech: v0.8.2-0-g02e4c76\n",
            "2020-08-24 16:43:12.104037: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "Loaded model in 0.00996s.\n",
            "Loading scorer from files deepspeech-0.8.2-models/deepspeech-0.8.1-models.scorer\n",
            "Loaded scorer in 0.000286s.\n",
            "Running inference.\n",
            "experience proves this\n",
            "Inference took 0.768s for 1.975s audio file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSENx8jhQGIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "41994e65-41e1-4496-e633-a0637bf408fa"
      },
      "source": [
        "!deepspeech --model deepspeech-0.8.2-models/deepspeech-0.8.1-models.pbmm --scorer deepspeech-0.8.2-models/deepspeech-0.8.1-models.scorer --audio ./audio/4507-16021-0012.wav"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from file deepspeech-0.8.2-models/deepspeech-0.8.1-models.pbmm\n",
            "TensorFlow: v2.2.0-24-g1c1b2b9\n",
            "DeepSpeech: v0.8.2-0-g02e4c76\n",
            "2020-08-24 16:43:24.364009: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "Loaded model in 0.0125s.\n",
            "Loading scorer from files deepspeech-0.8.2-models/deepspeech-0.8.1-models.scorer\n",
            "Loaded scorer in 0.000213s.\n",
            "Running inference.\n",
            "why should one hall on the way\n",
            "Inference took 1.052s for 2.735s audio file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSAovXUJQLjP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "536de7b2-634a-4a3b-d493-f70800772b9a"
      },
      "source": [
        "!deepspeech --model deepspeech-0.8.2-models/deepspeech-0.8.1-models.pbmm --scorer deepspeech-0.8.2-models/deepspeech-0.8.1-models.scorer --audio ./audio/8455-210777-0068.wav"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from file deepspeech-0.8.2-models/deepspeech-0.8.1-models.pbmm\n",
            "TensorFlow: v2.2.0-24-g1c1b2b9\n",
            "DeepSpeech: v0.8.2-0-g02e4c76\n",
            "2020-08-24 16:43:47.018632: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "Loaded model in 0.00975s.\n",
            "Loading scorer from files deepspeech-0.8.2-models/deepspeech-0.8.1-models.scorer\n",
            "Loaded scorer in 0.000193s.\n",
            "Running inference.\n",
            "your power is sufficient i said\n",
            "Inference took 1.040s for 2.590s audio file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZhiMZtSUZBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "92ab2650-b00b-497a-aa60-989cc431f975"
      },
      "source": [
        "!deepspeech --help"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: deepspeech [-h] --model MODEL [--scorer SCORER] --audio AUDIO\n",
            "                  [--beam_width BEAM_WIDTH] [--lm_alpha LM_ALPHA]\n",
            "                  [--lm_beta LM_BETA] [--version] [--extended] [--json]\n",
            "                  [--candidate_transcripts CANDIDATE_TRANSCRIPTS]\n",
            "\n",
            "Running DeepSpeech inference.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model MODEL         Path to the model (protocol buffer binary file)\n",
            "  --scorer SCORER       Path to the external scorer file\n",
            "  --audio AUDIO         Path to the audio file to run (WAV format)\n",
            "  --beam_width BEAM_WIDTH\n",
            "                        Beam width for the CTC decoder\n",
            "  --lm_alpha LM_ALPHA   Language model weight (lm_alpha). If not specified,\n",
            "                        use default from the scorer package.\n",
            "  --lm_beta LM_BETA     Word insertion bonus (lm_beta). If not specified, use\n",
            "                        default from the scorer package.\n",
            "  --version             Print version and exits\n",
            "  --extended            Output string from extended metadata\n",
            "  --json                Output json from metadata with timestamp of each word\n",
            "  --candidate_transcripts CANDIDATE_TRANSCRIPTS\n",
            "                        Number of candidate transcripts to include in JSON\n",
            "                        output\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJT6z1-uQQZ1",
        "colab_type": "text"
      },
      "source": [
        "Examine the output of the last three commands, and you will see results *“experience proof less”*, *“why should one halt on the way”*, and *“your power is sufficient i said”* respectively. You are all set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p61UrYSvQrOd",
        "colab_type": "text"
      },
      "source": [
        "# DeepSpeech API\n",
        "\n",
        "1.   **Import deepspeech**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKwSvpvaRFIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import deepspeech"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqd6bQ_gRPOB",
        "colab_type": "text"
      },
      "source": [
        "2. **Create a model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKDVOmbFRR1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file_path = 'deepspeech-0.8.2-models/deepspeech-0.8.1-models.pbmm'\n",
        "model = deepspeech.Model(model_file_path)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNRxsb2zRgeJ",
        "colab_type": "text"
      },
      "source": [
        "3. **Add scorer and other parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FRX1EvDRnLH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5366534c-014e-4551-89e1-54b4417b8d33"
      },
      "source": [
        "scorer_file_path = 'deepspeech-0.8.2-models/deepspeech-0.8.1-models.scorer'\n",
        "model.enableExternalScorer(scorer_file_path)\n",
        "\n",
        "lm_alpha = 0.75\n",
        "lm_beta = 1.85\n",
        "model.setScorerAlphaBeta(lm_alpha, lm_beta)\n",
        "\n",
        "beam_width = 500\n",
        "model.setBeamWidth(beam_width)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWbHnlwCRuDo",
        "colab_type": "text"
      },
      "source": [
        "## Batch API\n",
        "\n",
        "1.   **Read an input wav file**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRshwTMoSFEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wave\n",
        "filename = 'audio/8455-210777-0068.wav'\n",
        "w = wave.open(filename, 'r')\n",
        "rate = w.getframerate()\n",
        "frames = w.getnframes()\n",
        "buffer = w.readframes(frames)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAowLS39SNC_",
        "colab_type": "text"
      },
      "source": [
        "Checkout sample rate and buffer type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHvatdmxSYGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7a8a49e0-02e6-4e4c-fb49-efc55092cf8c"
      },
      "source": [
        "print(rate)\n",
        "print(model.sampleRate())\n",
        "print(str(type(buffer)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16000\n",
            "16000\n",
            "<class 'bytes'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOhbO3iTS3ft",
        "colab_type": "text"
      },
      "source": [
        "As you can see that the speech sample rate of the wav file is 16000hz, same as the model’s sample rate. But the buffer is a byte array, whereas DeepSpeech model expects 16-bit int array.\n",
        "\n",
        "2.  **Convert byte array buffer to int16 array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYXF6AU2S8m2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b690b551-bbbc-40aa-f73b-9a6571a09fcf"
      },
      "source": [
        "import numpy as np\n",
        "data16 = np.frombuffer(buffer, dtype=np.int16)\n",
        "print(str(type(data16)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyIxzx1zTVFp",
        "colab_type": "text"
      },
      "source": [
        "3.  **Run speech-to-text in batch mode to get the text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdzZteC7TZDP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f534f00f-0f2b-4bc4-ce23-7117aba01bb4"
      },
      "source": [
        "text = model.stt(data16)\n",
        "print(text)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "your power is sufficient i said\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUCXp-5uTh0L",
        "colab_type": "text"
      },
      "source": [
        "## Streaming API\n",
        "\n",
        "Now let’s accomplish the same using streaming API. It consists of 3 steps: open session, feed data, close session.\n",
        "\n",
        "1.  **Open a streaming session**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMSQ2VYCTyao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_stream = model.createStream()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK4QDAZtT3QZ",
        "colab_type": "text"
      },
      "source": [
        "2.  **Repeatedly feed chunks of speech buffer, and get interim results if desired**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScS6c2QQT72-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "9fae0476-68f0-42cd-caf7-02db228173ee"
      },
      "source": [
        "buffer_len = len(buffer)\n",
        "offset = 0\n",
        "batch_size = 16384\n",
        "text = ''\n",
        "while offset < buffer_len:\n",
        "    end_offset = offset + batch_size\n",
        "    chunk = buffer[offset:end_offset]\n",
        "    data16 = np.frombuffer(chunk, dtype=np.int16)\n",
        "    ds_stream.feedAudioContent(data16)\n",
        "    text = ds_stream.intermediateDecode()\n",
        "    print(text)\n",
        "    offset = end_offset"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "your power i\n",
            "your power is suffi\n",
            "your power is sufficient i said\n",
            "your power is sufficient i said\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeV7x1NgUK-p",
        "colab_type": "text"
      },
      "source": [
        "3.  **Close stream and get the final result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS0WtnF5UM4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9510fca-35c5-467f-95ac-b4ab825d5bc0"
      },
      "source": [
        "text = ds_stream.finishStream()\n",
        "print(text)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "your power is sufficient i said\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-vbd5CmUmsY",
        "colab_type": "text"
      },
      "source": [
        "Verify that the output is same as as the batch API output: \"your power is sufficient i said.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVNGdkq0fV-n",
        "colab_type": "text"
      },
      "source": [
        "# Recap\n",
        "\n",
        "DeepSpeech has two modes: batch and streaming. First step is to create a model object, and then either call `stt()` or `feedAudioContnet()` to transcribe audio to text.\n",
        "<br/>\n",
        "\n",
        "---\n",
        "&copy; 2020 Satish Chandra Gupta"
      ]
    }
  ]
}