{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mozilla_deepspeech_api_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scgupta/yearn2learn/blob/master/speech/asr/deepspeech/mozilla_deepspeech_api_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utrU3Ul7KK0G",
        "colab_type": "text"
      },
      "source": [
        "# Mozilla DeepSpeech API Exploration\n",
        "\n",
        "Mozilla released [DeepSpeech 0.6](https://github.com/mozilla/DeepSpeech/releases/tag/v0.6.0) with [APIs in C, Java, .NET, Python, and JavaScript](https://deepspeech.readthedocs.io/en/v0.6.0/Python-API.html).\n",
        "\n",
        "From Colab menu, select: **Runtime** > **Change runtime type**, and verify that it is set to Python3, and select GPU if you want to try out GPU version.\n",
        "\n",
        "You can install DeepSpeech with pip (make it deepspeech-gpu==0.6.0 if you are using GPU in colab runtime):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iemeuv-jKR3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zABV65yhNJ0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install deepspeech==0.6.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbWIPOUwNVyI",
        "colab_type": "text"
      },
      "source": [
        "## Download Models and Audio Files\n",
        "\n",
        "Mozilla has released models for US English, we will use those in this code lab.\n",
        "\n",
        "1. **Download the models:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxa0os-3OA1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0/deepspeech-0.6.0-models.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K-ikRBuOSoR",
        "colab_type": "text"
      },
      "source": [
        "2. **Unzip the downloaded models:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ_0XlmMOjFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xvzf deepspeech-0.6.0-models.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zui7wAB5OmlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l ./deepspeech-0.6.0-models/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g5hZVWXO1wl",
        "colab_type": "text"
      },
      "source": [
        "3. **Download audio data files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8r7m0zlO_BJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0/audio-0.6.0.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4yZaht2PH_5",
        "colab_type": "text"
      },
      "source": [
        "4. **Unzip audio files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82DLg4JpPOVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xvzf audio-0.6.0.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zExydudVPU4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls ./audio/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIiwclaXPzfm",
        "colab_type": "text"
      },
      "source": [
        "5. **Test that it all works**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlXV9XlpP8k2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!deepspeech --model deepspeech-0.6.0-models/output_graph.pb --lm deepspeech-0.6.0-models/lm.binary --trie ./deepspeech-0.6.0-models/trie --audio ./audio/2830-3980-0043.wav"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSENx8jhQGIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!deepspeech --model deepspeech-0.6.0-models/output_graph.pb --lm deepspeech-0.6.0-models/lm.binary --trie ./deepspeech-0.6.0-models/trie --audio ./audio/4507-16021-0012.wav"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSAovXUJQLjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!deepspeech --model deepspeech-0.6.0-models/output_graph.pb --lm deepspeech-0.6.0-models/lm.binary --trie ./deepspeech-0.6.0-models/trie --audio ./audio/8455-210777-0068.wav"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJT6z1-uQQZ1",
        "colab_type": "text"
      },
      "source": [
        "Examine the output of the last three commands, and you will see results *“experience proof less”*, *“why should one halt on the way”*, and *“your power is sufficient i said”* respectively. You are all set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p61UrYSvQrOd",
        "colab_type": "text"
      },
      "source": [
        "# DeepSpeech API\n",
        "\n",
        "1.   **Import deepspeech**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKwSvpvaRFIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import deepspeech"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqd6bQ_gRPOB",
        "colab_type": "text"
      },
      "source": [
        "2. **Create a model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKDVOmbFRR1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file_path = 'deepspeech-0.6.0-models/output_graph.pbmm'\n",
        "beam_width = 500\n",
        "model = deepspeech.Model(model_file_path, beam_width)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNRxsb2zRgeJ",
        "colab_type": "text"
      },
      "source": [
        "3. **Add language model for better accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FRX1EvDRnLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm_file_path = 'deepspeech-0.6.0-models/lm.binary'\n",
        "trie_file_path = 'deepspeech-0.6.0-models/trie'\n",
        "lm_alpha = 0.75\n",
        "lm_beta = 1.85\n",
        "model.enableDecoderWithLM(lm_file_path, trie_file_path, lm_alpha, lm_beta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWbHnlwCRuDo",
        "colab_type": "text"
      },
      "source": [
        "## Batch API\n",
        "\n",
        "1.   **Read an input wav file**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRshwTMoSFEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wave\n",
        "filename = 'audio/8455-210777-0068.wav'\n",
        "w = wave.open(filename, 'r')\n",
        "rate = w.getframerate()\n",
        "frames = w.getnframes()\n",
        "buffer = w.readframes(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAowLS39SNC_",
        "colab_type": "text"
      },
      "source": [
        "Checkout sample rate and buffer type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHvatdmxSYGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(rate)\n",
        "print(model.sampleRate())\n",
        "print(str(type(buffer)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOhbO3iTS3ft",
        "colab_type": "text"
      },
      "source": [
        "As you can see that the speech sample rate of the wav file is 16000hz, same as the model’s sample rate. But the buffer is a byte array, whereas DeepSpeech model expects 16-bit int array.\n",
        "\n",
        "2.  **Convert byte array buffer to int16 array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYXF6AU2S8m2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "data16 = np.frombuffer(buffer, dtype=np.int16)\n",
        "print(str(type(data16)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyIxzx1zTVFp",
        "colab_type": "text"
      },
      "source": [
        "3.  **Run speech-to-text in batch mode to get the text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdzZteC7TZDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = model.stt(data16)\n",
        "print(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUCXp-5uTh0L",
        "colab_type": "text"
      },
      "source": [
        "## Streaming API\n",
        "\n",
        "Now let’s accomplish the same using streaming API. It consists of 3 steps: open session, feed data, close session.\n",
        "\n",
        "1.  **Open a streaming session**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMSQ2VYCTyao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context = model.createStream()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK4QDAZtT3QZ",
        "colab_type": "text"
      },
      "source": [
        "2.  **Repeatedly feed chunks of speech buffer, and get interim results if desired**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScS6c2QQT72-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "buffer_len = len(buffer)\n",
        "offset = 0\n",
        "batch_size = 16384\n",
        "text = ''\n",
        "while offset < buffer_len:\n",
        "    end_offset = offset + batch_size\n",
        "    chunk = buffer[offset:end_offset]\n",
        "    data16 = np.frombuffer(chunk, dtype=np.int16)\n",
        "    model.feedAudioContent(context, data16)\n",
        "    text = model.intermediateDecode(context)\n",
        "    print(text)\n",
        "    offset = end_offset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeV7x1NgUK-p",
        "colab_type": "text"
      },
      "source": [
        "3.  **Close stream and get the final result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS0WtnF5UM4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = model.finishStream(context)\n",
        "print(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-vbd5CmUmsY",
        "colab_type": "text"
      },
      "source": [
        "Verify that the output is same as as the batch API output: \"your power is sufficient i said.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVNGdkq0fV-n",
        "colab_type": "text"
      },
      "source": [
        "# Recap\n",
        "\n",
        "DeepSpeech has two modes: batch and streaming. First step is to create a model object, and then either call `stt()` or `feedAudioContnet()` to transcribe audio to text.",
        "\n",
        "<br/>\n",
        "\n",
        "---\n",
        "&copy; 2020 Satish Chandra Gupta"
      ]
    }
  ]
}
